{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b67149cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T00:17:36.481255Z",
     "iopub.status.busy": "2023-12-02T00:17:36.480899Z",
     "iopub.status.idle": "2023-12-02T00:18:21.342310Z",
     "shell.execute_reply": "2023-12-02T00:18:21.341044Z"
    },
    "papermill": {
     "duration": 44.869473,
     "end_time": "2023-12-02T00:18:21.344813",
     "exception": false,
     "start_time": "2023-12-02T00:17:36.475340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qq --no-deps /kaggle/input/daigt-pip/peft-0.6.0-py3-none-any.whl\n",
    "#!pip install -qq --no-deps /kaggle/input/daigt-pip/transformers-4.35.0-py3-none-any.whl\n",
    "#!pip install -qq --no-deps /kaggle/input/daigt-pip/tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install -qq --no-deps /kaggle/input/daigt-pip/optimum-1.14.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172c7116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T00:18:21.354218Z",
     "iopub.status.busy": "2023-12-02T00:18:21.353892Z",
     "iopub.status.idle": "2023-12-02T00:18:40.125196Z",
     "shell.execute_reply": "2023-12-02T00:18:40.124433Z"
    },
    "papermill": {
     "duration": 18.778647,
     "end_time": "2023-12-02T00:18:40.127547",
     "exception": false,
     "start_time": "2023-12-02T00:18:21.348900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from transformers import EarlyStoppingCallback\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import sklearn\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import DistilBertTokenizerFast, AutoModelForSequenceClassification, Trainer\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "from accelerate import cpu_offload, dispatch_model\n",
    "from accelerate.utils.modeling import infer_auto_device_map\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from peft import LoraConfig, TaskType\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import accelerate\n",
    "import transformers\n",
    "from transformers import (\n",
    "\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c555c79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T00:18:40.137574Z",
     "iopub.status.busy": "2023-12-02T00:18:40.136350Z",
     "iopub.status.idle": "2023-12-02T00:18:40.143854Z",
     "shell.execute_reply": "2023-12-02T00:18:40.143139Z"
    },
    "papermill": {
     "duration": 0.013902,
     "end_time": "2023-12-02T00:18:40.145647",
     "exception": false,
     "start_time": "2023-12-02T00:18:40.131745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "995b6199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T00:18:40.154484Z",
     "iopub.status.busy": "2023-12-02T00:18:40.154210Z",
     "iopub.status.idle": "2023-12-02T00:19:03.558453Z",
     "shell.execute_reply": "2023-12-02T00:19:03.557645Z"
    },
    "papermill": {
     "duration": 23.411449,
     "end_time": "2023-12-02T00:19:03.560731",
     "exception": false,
     "start_time": "2023-12-02T00:18:40.149282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/transformers/distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/transformers/roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/transformers/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/huggingface-albert-v2/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# Define the ensembling weights for each model\n",
    "model_weights = [0.1, 0.05, 0, 0.99, 0]\n",
    "test_data = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\")\n",
    "X_test = list(test_data[\"text\"])\n",
    "\n",
    "\n",
    "tokenizers = [\n",
    "    AutoTokenizer.from_pretrained('/kaggle/input/dis-lora/dis_lora_token/content/token'),\n",
    "    AutoTokenizer.from_pretrained('/kaggle/input/roberta-loraa/token2/content/token'),\n",
    "    AutoTokenizer.from_pretrained('/kaggle/input/unbert-loraa/token_unbert_lora/content/token'),\n",
    "    AutoTokenizer.from_pretrained('/kaggle/input/albertlora-v3/tokenizer/content/tokenizer_albert'),\n",
    "    AutoTokenizer.from_pretrained('/kaggle/input/xlnet-lora/tokenizer_xlnet/content/tokenizer_xlnet')\n",
    "]\n",
    "\n",
    "model = []\n",
    "\n",
    "foundation_model = AutoModelForSequenceClassification.from_pretrained('/kaggle/input/transformers/distilbert-base-uncased',num_labels=1, )\n",
    "model1 = PeftModel.from_pretrained(foundation_model, '/kaggle/input/dis-lora/dis_lora_model/content/model', is_trainable=False).to('cuda')\n",
    "model.append(model1)\n",
    "\n",
    "\n",
    "foundation_model = AutoModelForSequenceClassification.from_pretrained('/kaggle/input/transformers/roberta-base',num_labels=1, )\n",
    "model2 = PeftModel.from_pretrained(foundation_model, '/kaggle/input/roberta-loraa/model2/content/model', is_trainable=False).to('cuda')\n",
    "model.append(model2)\n",
    "\n",
    "\n",
    "foundation_model = AutoModelForSequenceClassification.from_pretrained('/kaggle/input/transformers/bert-base-uncased',num_labels=1, )\n",
    "model3 = PeftModel.from_pretrained(foundation_model, '/kaggle/input/unbert-loraa/model_unbert_lora/content/model', is_trainable=False).to('cuda')\n",
    "model.append(model3)\n",
    "\n",
    "\n",
    "foundation_model = AutoModelForSequenceClassification.from_pretrained('/kaggle/input/huggingface-albert-v2/albert-base-v2',num_labels=1, )\n",
    "model4 = PeftModel.from_pretrained(foundation_model, '/kaggle/input/albertlora-v3/model_3/content/albert', is_trainable=False).to('cuda')\n",
    "model.append(model4)\n",
    "\n",
    "\n",
    "foundation_model = AutoModelForSequenceClassification.from_pretrained('/kaggle/input/xlnet-1/file_4/content/output/checkpoint-2500',num_labels=1, )\n",
    "model5 = PeftModel.from_pretrained(foundation_model, '/kaggle/input/xlnet-lora/xlnet/content/xlnet', is_trainable=False).to('cuda')\n",
    "model.append(model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b4e4ee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T00:19:03.570910Z",
     "iopub.status.busy": "2023-12-02T00:19:03.570241Z",
     "iopub.status.idle": "2023-12-02T00:19:06.983919Z",
     "shell.execute_reply": "2023-12-02T00:19:06.982677Z"
    },
    "papermill": {
     "duration": 3.421229,
     "end_time": "2023-12-02T00:19:06.986376",
     "exception": false,
     "start_time": "2023-12-02T00:19:03.565147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the predictions on the test set using a weighted ensemble\n",
    "predictions = torch.zeros(len(test_data), 1, device='cuda')\n",
    "for i, model in enumerate(model):\n",
    "    tokenizer = tokenizers[i]\n",
    "    test_dataset = Dataset(X_test, tokenizer, max_len=512)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, num_workers=4)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j, batch in enumerate(test_loader):\n",
    "            input_ids = batch['input_ids'].to('cuda')\n",
    "            attention_mask = batch['attention_mask'].to('cuda')\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            predictions[j*8:(j+1)*8, :] += model_weights[i] * logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c5efa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T00:19:06.996889Z",
     "iopub.status.busy": "2023-12-02T00:19:06.996134Z",
     "iopub.status.idle": "2023-12-02T00:19:07.002106Z",
     "shell.execute_reply": "2023-12-02T00:19:07.001155Z"
    },
    "papermill": {
     "duration": 0.013315,
     "end_time": "2023-12-02T00:19:07.004163",
     "exception": false,
     "start_time": "2023-12-02T00:19:06.990848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26/2822908032.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_pred = (torch.tensor(predictions)).cpu().numpy().ravel()\n"
     ]
    }
   ],
   "source": [
    "test_pred = (torch.tensor(predictions)).cpu().numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31c8a659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T00:19:07.013938Z",
     "iopub.status.busy": "2023-12-02T00:19:07.013674Z",
     "iopub.status.idle": "2023-12-02T00:19:07.022763Z",
     "shell.execute_reply": "2023-12-02T00:19:07.021968Z"
    },
    "papermill": {
     "duration": 0.016139,
     "end_time": "2023-12-02T00:19:07.024583",
     "exception": false,
     "start_time": "2023-12-02T00:19:07.008444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({\n",
    "    'id': test_data['id'],\n",
    "    'prediction': test_pred\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "452fd829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T00:19:07.034130Z",
     "iopub.status.busy": "2023-12-02T00:19:07.033611Z",
     "iopub.status.idle": "2023-12-02T00:19:07.046850Z",
     "shell.execute_reply": "2023-12-02T00:19:07.046047Z"
    },
    "papermill": {
     "duration": 0.019963,
     "end_time": "2023-12-02T00:19:07.048645",
     "exception": false,
     "start_time": "2023-12-02T00:19:07.028682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.139474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.080989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>-0.012128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prediction\n",
       "0  0000aaaa    0.139474\n",
       "1  1111bbbb    0.080989\n",
       "2  2222cccc   -0.012128"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d621571e",
   "metadata": {
    "papermill": {
     "duration": 0.004088,
     "end_time": "2023-12-02T00:19:07.057027",
     "exception": false,
     "start_time": "2023-12-02T00:19:07.052939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6888007,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 1455358,
     "sourceId": 2468672,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3591146,
     "sourceId": 6249137,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3942644,
     "sourceId": 6890527,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3972872,
     "sourceId": 6921012,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4020999,
     "sourceId": 6995426,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4026254,
     "sourceId": 7003573,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4056317,
     "sourceId": 7048736,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4079792,
     "sourceId": 7081928,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4079801,
     "sourceId": 7082353,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4085685,
     "sourceId": 7090263,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4085967,
     "sourceId": 7090649,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4089222,
     "sourceId": 7095406,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 97.549146,
   "end_time": "2023-12-02T00:19:10.659745",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-02T00:17:33.110599",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
